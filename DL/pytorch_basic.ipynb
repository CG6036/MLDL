{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNNxJPj88oNlChr2nyVxUzh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1. Tensor"],"metadata":{"id":"PXy74SIg-tAf"}},{"cell_type":"code","source":["import torch"],"metadata":{"id":"LyWLp4xt-ndi","executionInfo":{"status":"ok","timestamp":1682838486094,"user_tz":-540,"elapsed":4624,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["t1 = torch.zeros(4,2)\n","print(t1)\n","print(t1.shape)\n","print(t1.dtype)\n","print(t1.device)\n","\n","t2 = torch.rand(2)\n","print(\"t2: \")\n","print(t2)\n","print(t2.shape)\n","\n","print(\"\\n---after unsqueeze---\")\n","t2_add_rank = t2.unsqueeze(0)\n","print(t2_add_rank)\n","print(t2_add_rank.shape)\n","\n","t4 = torch.rand(192) # 3*8*8\n","print(t4.shape)\n","\n","t4 = t4.reshape(3, 8, 8)\n","print(\"\\n---after reshape---\")\n","print(t4.shape)\n","\n","t4 = t4.permute(1,2,0)\n","print(\"\\n---after permute---\")\n","print(t4.shape)\n","\n","# Attribute - device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","# t1_gpu = t1.cuda(device) \n","# print(t1_gpu.device)     \n","# print(t1.device)         "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gDLLkZxq_TIb","executionInfo":{"status":"ok","timestamp":1682838652556,"user_tz":-540,"elapsed":2,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"8d02579b-4353-4601-a8a9-2efa636d5acb"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0.],\n","        [0., 0.],\n","        [0., 0.],\n","        [0., 0.]])\n","torch.Size([4, 2])\n","torch.float32\n","cpu\n","t2: \n","tensor([0.1567, 0.0490])\n","torch.Size([2])\n","\n","---after unsqueeze---\n","tensor([[0.1567, 0.0490]])\n","torch.Size([1, 2])\n","torch.Size([192])\n","\n","---after reshape---\n","torch.Size([3, 8, 8])\n","\n","---after permute---\n","torch.Size([8, 8, 3])\n","cpu\n"]}]},{"cell_type":"code","source":["# 실제 값 이동 확인\n","t5 = torch.rand(12)\n","print('\\n', t5)\n","t5 = t5.reshape(3,2,2)\n","print('\\n', t5)\n","t5= t5.permute(1,2,0) #(2,2,3)\n","print('\\n',t5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LUn8o2jj_YYa","executionInfo":{"status":"ok","timestamp":1682838882913,"user_tz":-540,"elapsed":5,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"c315605d-b410-49b6-88c2-451129153630"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," tensor([0.1940, 0.0196, 0.1662, 0.2216, 0.9325, 0.3869, 0.6377, 0.5002, 0.8160,\n","        0.7854, 0.4394, 0.3555])\n","\n"," tensor([[[0.1940, 0.0196],\n","         [0.1662, 0.2216]],\n","\n","        [[0.9325, 0.3869],\n","         [0.6377, 0.5002]],\n","\n","        [[0.8160, 0.7854],\n","         [0.4394, 0.3555]]])\n","\n"," tensor([[[0.1940, 0.9325, 0.8160],\n","         [0.0196, 0.3869, 0.7854]],\n","\n","        [[0.1662, 0.6377, 0.4394],\n","         [0.2216, 0.5002, 0.3555]]])\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch"],"metadata":{"id":"Syh334e_A4RP","executionInfo":{"status":"ok","timestamp":1682846619024,"user_tz":-540,"elapsed":5603,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# basic operations\n","# numpy에서 tensor로 옮기는 과정이 필요하다\n","\n","# convert numpy -> tensor\n","num_array = np.array([[1,2],[3,4]])\n","t5 = torch.Tensor(num_array)\n","print(type(num_array))\n","print(num_array)\n","print(type(t5))\n","print(t5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWZJSCJRCEBh","executionInfo":{"status":"ok","timestamp":1682846619024,"user_tz":-540,"elapsed":11,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"d5de2696-c0d3-4754-c0a8-9448f8a9abb5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n","[[1 2]\n"," [3 4]]\n","<class 'torch.Tensor'>\n","tensor([[1., 2.],\n","        [3., 4.]])\n"]}]},{"cell_type":"code","source":["# elementwise operations\n","t6 = torch.ones_like(t5) # tesnor filled w/ value '1' in the same shape of t5\n","output = t5 + 2 * t6\n","print(output)\n","\n","print()\n","print(\"exponential: \")\n","print(torch.exp(output))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7XY8tLuFCXnH","executionInfo":{"status":"ok","timestamp":1682846619024,"user_tz":-540,"elapsed":7,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"1a49fb76-5235-42d5-b0a9-05d98a63b48e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3., 4.],\n","        [5., 6.]])\n","\n","exponential: \n","tensor([[ 20.0855,  54.5981],\n","        [148.4132, 403.4288]])\n"]}]},{"cell_type":"code","source":["# broadcasting\n","vector = torch.ones((2,1)) # shape: (2,1)\n","broadcast_output = output + vector\n","print(broadcast_output)\n","\n","vector_err = torch.ones((3,1)) # shape: (3,1)\n","# broadcast_output = output + vector_err # Raise Error!"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Em2FMnO2CvzN","executionInfo":{"status":"ok","timestamp":1682846619025,"user_tz":-540,"elapsed":6,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"d73e3cec-5d84-4a48-cd23-d99634a8724b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[4., 5.],\n","        [6., 7.]])\n"]}]},{"cell_type":"code","source":["# dimension reduction\n","t7  = torch.randn(2,3,4) # shape: (2,3,4) = (0th dim, 1st dim, 2nd dim)\n","# rank가 3개\n","# 앞 뒤로 3x4 matrix가 각 1개씩 있다는 것. 즉 2개 있다는 뜻\n","print(t7)\n","print()\n","\n","# argmax는 가장 큰 값을 가진 위치를 뽑는, index를 뽑는 함수\n","# 'dim = 1'은 dimension 1에 해당하는 것끼리 비교하겠다는 것. \n","# dimension 0이 2, 1이 3, 2가 4이므로 여기에서는 앞, 뒤 3X4 matrix에서 3에 해당하는 것 중에서 제일 큰 것의 위치를 뽑겠다.\n","# 3에 해당하는 것 중에 1개만 뽑으니까 1이 되고, 2X4가 되는 것. 2X4 matrix를 뽑겠다는 생각이다.\n","t7_argmax = torch.argmax(t7, dim=1)\n","print(t7_argmax.shape) # rank가 2개로 자동으로 줄었다.\n","print(t7_argmax)\n","\n","print()\n","\n","# rank를 줄이지 않고 유지를 해야할 때가 있다. keepdims = True로 해주면 된다.\n","print(torch.argmax(t7, 1, keepdims=True).shape) \n","# print(torch.argmax(t7, 1, keepdims=True))\n","# squeeze를 1로 한다는 것은 2X3X4에서 3에 해당하는 것을 줄이겠다는 뜻이다. 2X4가 된다. 위와 동일한 결과가 나온다.\n","print(torch.argmax(t7, 1, keepdims=True).squeeze(1).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wfFY3qr8DYbV","executionInfo":{"status":"ok","timestamp":1682846619025,"user_tz":-540,"elapsed":4,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"75ce2e48-885c-4e38-d242-60ef647c76fb"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[-0.1916,  0.2789, -1.1285,  1.3264],\n","         [-0.1826,  0.5047, -0.6547, -0.5838],\n","         [ 1.4835, -0.1682, -0.0951,  1.1563]],\n","\n","        [[ 1.3895, -0.9026,  0.6342,  0.6280],\n","         [ 0.5826, -1.6360,  0.6985,  1.7466],\n","         [-1.0100,  0.3689,  1.5041, -0.3104]]])\n","\n","torch.Size([2, 4])\n","tensor([[2, 1, 2, 0],\n","        [0, 2, 2, 1]])\n","\n","torch.Size([2, 1, 4])\n","torch.Size([2, 4])\n"]}]},{"cell_type":"markdown","source":["# Data"],"metadata":{"id":"AX9upH8hheyJ"}},{"cell_type":"markdown","source":["torch.utils.data.Dataset\n","  A python class defining a Dataset\n","  Called by DataLoader implicitly\n","  Need to implement the floowing methods:\n","    __init__: initialize dir/file to read images, transform\n","    __getitem__:loads data from dataset at a given index\n","    __len__:returns the size of dataset\n","\n","torch.utils.data.DataLoader\n","  Dataset을 model로 전달\n","  Parameters\n","    batch_size(default = 1)\n","    shuffle     \n","    num_workers # 병렬 처리와 관련된 내용"],"metadata":{"id":"63LysXzthP3Y"}},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"],"metadata":{"id":"f0cRebVmihwx","executionInfo":{"status":"ok","timestamp":1682848654733,"user_tz":-540,"elapsed":6,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class SimpleDataset(Dataset):\n","\n","  # Initializes csv_file(annotation) and root_dir storing the data\n","  # (optional) initializes transformations\n","  def __init__(self, csv_file=None, root_dir=None):\n","\n","    #self.csv_file = csv_file\n","    #self.root_dir = root_dir\n","    self.x_data = torch.rand(100, 4)\n","    self.y_data = torch.rand(100, 1)\n","\n","  # Provides the size of dataset\n","  def __len__(self):\n","    return len(self.x_data)\n","\n","  # Provides a sample data given idx\n","  def __getitem__(self, idx):\n","    x = torch.FloatTensor(self.x_data[idx])\n","    y = torch.FloatTensor(self.y_data[idx])\n","    return x, y"],"metadata":{"id":"ipmtN0uDmGyg","executionInfo":{"status":"ok","timestamp":1682848763974,"user_tz":-540,"elapsed":4,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["dataset = SimpleDataset() \n","# Number of samples in a mini-batch: 25\n","# Shuffles dataset before sampling\n","dataloader = DataLoader(dataset, batch_size=25, shuffle=True)"],"metadata":{"id":"XdYl2z_AmkzA","executionInfo":{"status":"ok","timestamp":1682848788775,"user_tz":-540,"elapsed":3,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# collate_fn\n","# Dataloader의 batch 단위로 input을 process하기 위한 작업(post-processing)\n","  # e.g. 서로 길이가 다른 input에 zero-padding을 추가해 길이 맞춰주기\n","  # 길이가 다르면 같은 batch로 묶이지 않는다. ㅡ\n","\n","def collate_fn(self, data):\n","  max_len = 10\n","  batch = []\n","  for x, y in data:\n","    x_padded = torch.cat([x, torch.zeros(max_len - x.shape[0])])\n","    batch.append(x_padded)\n","  return torch.stack(batch)"],"metadata":{"id":"R7i3CAjbmqp6","executionInfo":{"status":"ok","timestamp":1682850674453,"user_tz":-540,"elapsed":3,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["dataset = SimpleDataset() \n","dataloader = DataLoader(dataset, batch_size=25, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GgRiIoL2q8Vq","executionInfo":{"status":"ok","timestamp":1682849936797,"user_tz":-540,"elapsed":5,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"a6136594-79bd-4a58-e4e1-a6fddfd40114"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function Tensor.size>"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["# 2. Dataset & Dataloader"],"metadata":{"id":"EgTCf2f0q9VM"}},{"cell_type":"code","source":["# Define dataset & dataloader\n","\n","import torch\n","import numpy as np\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import random\n","\n","class SimpleDataset(Dataset):\n","\n","  def __init__(self, csv_file=None, root_dir=None):\n","\n","    #self.csv_file = csv_file\n","    #self.root_dir = root_dir\n","\n","    # set x_data with random length\n","    n_dataset = 100\n","    self.x_data = []\n","    for _ in range(n_dataset):\n","      random_length = random.randint(5,10)\n","      self.x_data.append(np.random.randint(0,255,random_length))\n","    # set y_data\n","    self.y_data = torch.rand(n_dataset, 1)\n","\n","    print(\"SimpleDataset setting done\")\n","    print(f'x_data shape: {len(self.x_data)}')\n","    print(f'x_data random length (1st, 4th, 46th): {len(self.x_data[0]), len(self.x_data[3]), len(self.x_data[45])}')\n","    print(f'y_data shape: {self.y_data.shape}')\n","\n","  # Provides the size of dataset\n","  def __len__(self):\n","    return len(self.x_data)\n","\n","  # Provides a sample data given idx\n","  def __getitem__(self, idx):\n","    x = torch.FloatTensor(self.x_data[idx])\n","    y = torch.FloatTensor(self.y_data[idx])\n","    return x, y\n","\n","  # Zero padding\n","  # dataloader 입장에서 batch로 맞출 때 아래 function을 call한다.\n","  # zero padding 이외에 다른 목적으로 batch 구성 시 call하고 싶은 function이 있으면 \n","  # 다르게 정의해줘도 된다. \n","  def collate_fn(self, data):\n","    max_len = 10\n","    batch = []\n","    for x, y in data:\n","      x_padded = torch.cat([x, torch.zeros(max_len - x.shape[0])])\n","      batch.append(x_padded)\n","    return torch.stack(batch)\n","\n","# instance를 하나 만들어준 것\n","dataset = SimpleDataset()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFgdGNgIU0pF","executionInfo":{"status":"ok","timestamp":1682894986918,"user_tz":-540,"elapsed":4,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"2c5288af-ed28-4f4f-9cf4-b2dba74bcaea"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleDataset setting done\n","x_data shape: 100\n","x_data random length (1st, 4th, 46th): (10, 8, 10)\n","y_data shape: torch.Size([100, 1])\n"]}]},{"cell_type":"code","source":["# 100개 중 25개씩 배치를 묶으면 4묶음이 나온다.\n","dataloader = DataLoader(dataset, batch_size=25, collate_fn=dataset.collate_fn, shuffle=True)\n","# dataloader = DataLoader(datset, batch_size=25, shuffle True) # Raise Error!\n","\n","for batch_idx, samples in enumerate(dataloader):\n","  print(\"batch idx: \", batch_idx+1)\n","  print(\"sample shape: \", samples.shape)\n","\n","  if batch_idx == len(dataloader)-1:\n","    print(samples)\n","\n","  # ... train continued\n","  # 짧게 나온 것들은 0이 추가되어 있음. zero padding이 되어있다.\n","  # 같은 길이의 데이터만 return 할 수 있다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0LwMdLi6Wcqp","executionInfo":{"status":"ok","timestamp":1682895206862,"user_tz":-540,"elapsed":258,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"626beb47-f3bc-4010-9fc3-d9ce58ce4a5d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["batch idx:  1\n","sample shape:  torch.Size([25, 10])\n","batch idx:  2\n","sample shape:  torch.Size([25, 10])\n","batch idx:  3\n","sample shape:  torch.Size([25, 10])\n","batch idx:  4\n","sample shape:  torch.Size([25, 10])\n","tensor([[139.,  82.,  39., 155., 233.,  20., 191., 141., 172.,   0.],\n","        [ 40.,  31., 109., 162., 156., 201.,  74.,  74., 225.,   0.],\n","        [133.,  44., 195., 183.,  38., 192.,  59.,  96.,   0.,   0.],\n","        [167.,  91., 225., 166., 119.,  72., 180.,  91., 155.,   0.],\n","        [ 94.,  83.,  60., 233., 179.,   0.,   0.,   0.,   0.,   0.],\n","        [232., 117., 116., 244., 114.,  38., 145.,  76.,  63.,   0.],\n","        [214., 127., 254.,  66.,  44., 111., 139.,   0.,   0.,   0.],\n","        [107., 180., 203., 186.,  27., 228.,  70.,   0.,   0.,   0.],\n","        [ 34., 111., 119., 155., 231.,   6.,  12., 103.,   0.,   0.],\n","        [ 51., 244.,  71.,  26., 246., 182.,  97., 128., 202.,   0.],\n","        [ 62.,  94.,  47.,  28.,  23., 198., 218.,   0.,   0.,   0.],\n","        [ 98.,  24.,  98., 156., 172., 158., 222., 127.,   0.,   0.],\n","        [ 10., 181.,  20., 182.,  54.,  53.,   4., 242., 226.,   0.],\n","        [188.,  22.,  57., 164., 185., 225., 195., 206.,   0.,   0.],\n","        [133., 227.,  87., 177., 183.,  88.,  95., 120.,  32.,   0.],\n","        [161.,  89., 141., 189., 108.,  13.,  64., 213.,   0.,   0.],\n","        [250.,  62.,  11., 212., 107., 202.,   0.,   0.,   0.,   0.],\n","        [ 39.,  99.,  26., 235., 202., 216.,   0.,   0.,   0.,   0.],\n","        [ 85., 137., 165., 123.,  20.,  94., 233.,   0.,   0.,   0.],\n","        [  2., 213.,   6., 165.,  83.,  86.,  72.,  61., 226., 195.],\n","        [164., 162., 229., 180., 142.,   0.,   0.,   0.,   0.,   0.],\n","        [ 63.,  69.,  87., 128., 250.,  33.,  61.,  94.,   0.,   0.],\n","        [ 46., 107., 231.,  75., 210., 159., 133., 142.,  19., 151.],\n","        [192.,  49., 201., 196.,  63., 175.,  52.,   0.,   0.,   0.],\n","        [109., 152.,  37., 237., 224., 133.,  80., 244.,   0.,   0.]])\n"]}]},{"cell_type":"markdown","source":["#Defining a Model"],"metadata":{"id":"a4eWf2vmXvZD"}},{"cell_type":"markdown","source":["\n","1. Inherit nn.Module\n","2. Define __init__\n","  - weight을 포함하는 trainable layer\n","3. Define forward\n","  - weight을 포함하지 않는 fixed operation layer\n","    - e.g. softmax, relu\n","  - 위와 같은 함수는 learnable 하지 않기 때문에 init에 써줄 필요 없이\n","  - forward 함수에 곧바로 써준다.\n","  - Called automatically by __call__\n","  - Output = network(input)\n","4. Types of layers in Pytorch"],"metadata":{"id":"t7e3uewdZ1_7"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","# two-layer example\n","\n","class Net(nn.Module):\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    self.fc1 = nn.Linear(784,128)\n","    self.fc2 = nn.Linear(128,64)\n","    self.classifier = nn.Linear(64,10)\n","    # MNIST는 10개의 숫자를 classify 하는 것이기 때문에 10으로 설정한 것\n","    \n","  def forward(self, x):\n","    x = x.reshape(-1, 784)\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    return self.classifier(x)\n","\n","network = Net()\n","print(network)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZELnnrJwaH0c","executionInfo":{"status":"ok","timestamp":1682896072864,"user_tz":-540,"elapsed":6,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"727c03d6-e86e-4570-a1eb-4889a015586d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Net(\n","  (fc1): Linear(in_features=784, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=64, bias=True)\n","  (classifier): Linear(in_features=64, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"markdown","source":["#Training a Model"],"metadata":{"id":"lsJYjoGObC1m"}},{"cell_type":"markdown","source":["training을 할 때는 update를 해줘야 하고\n","test를 할 때는 바뀌면 안 되기 때문에 모드를 따로 설정해줘야 한다.\n","\n","1. Set train mode on\n"," - Train <-> eval\n"," - activate/deactivate some layers\n"," - (e.g., dropout, batch-norm..)\n","\n","2. Set optimization grad to zero for each mini-batch\n","\n","3. Copy the data to the device where the model exists.\n","\n","4. Backpropagation & update parameters."],"metadata":{"id":"hloisrzdcDFK"}},{"cell_type":"code","source":["def train(model, optim, loss_fn, train_loader, epochs, device):\n","  for epoch in range(epochs):\n","    train_loss = 0.0\n","    # Train mode로 전환\n","    model.train()\n","\n","    for batch in train_loader:\n","      # Initialize, gradient를 모두 0으로 만들어준다.\n","      # gradient를 다 계산해서 쌓을 건데, batch 별로 gradient를 쌓고 update를 하기 때문에\n","      # 새로운 batch가 들어올 때마다 초기화 해줘야 한다.\n","      optim.zero_grad()\n","\n","      input, target = batch\n","      # GPU 사용 시\n","      # 앞에서 모델 parameter를 모두 GPU에 올렸다면 아래 둘 다 같이 GPU에 올라가야 오류가 안 생긴다.\n","      input = input.to(device)\n","      target = target.to(device)\n","\n","      output = model(input)\n","      loss = loss_fn(output, target)\n","      loss.backward()\n","      optim.step()\n","      train_loss += loss.data.item()\n","    train_loss /= len(train_loader.dataset)\n","\n","    print(f'Epoch: {epoch+1}, Training Loss: {train_loss}')"],"metadata":{"id":"nqSaDx_ncnUl","executionInfo":{"status":"ok","timestamp":1682896853548,"user_tz":-540,"elapsed":253,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Testing a Model"],"metadata":{"id":"ayBJWOYZeBa9"}},{"cell_type":"markdown","source":["1. Set evaluation mode on\n","2. Set autograd engine off\n","  - Autograd: automatically track gradients"],"metadata":{"id":"-p5xnUsgeiVW"}},{"cell_type":"code","source":["def test(model, loss_fn, device):\n","  model.eval()\n","  test_loss = 0.0\n","  correct = 0\n","\n","  # with 문으로 감싸주는 이유는 test할 때는 background에서 autograd가 돌 필요가 없기 때문\n","  with torch.no_grad():\n","    for batch in test_loader:\n","      input, target = batch\n","      # GPU 사용 시\n","      input = input.to(device)\n","      target = target.to(device)\n","\n","      output = model(input)\n","      loss = loss_fn(output, target)\n","      test_loss += loss.data.item()\n","      pred = output.data.max(1, keepdim=True)[1]\n","      correct += pred.eq(target.data.view_as(pred)).sum().item()\n","    test_loss /= len(test_loader.dataset)\n","  print(f'Test Loss: {test_loss:.4f},\\t Accuracy: ({100. * correct / len(test_loader.dataset)}%)\\n')"],"metadata":{"id":"N9jISpRzesU3","executionInfo":{"status":"ok","timestamp":1682899984272,"user_tz":-540,"elapsed":375,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["optimizer = optim.SGD(network.parameters(), lr=1e-2, momentum = 0.9)\n","train(network, optimizer, nn.CrossEntropyLoss(), train_loader, num_epochs, device)\n","test(network, nn.CrossEntropyLoss(), device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A5lBKK09gTqp","executionInfo":{"status":"ok","timestamp":1682900023157,"user_tz":-540,"elapsed":37520,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"d1474a24-a2a0-43d5-8557-77942acf714a"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 0.0008659676497181257\n","Epoch: 2, Training Loss: 0.0007285783295713675\n","Epoch: 3, Training Loss: 0.0006259336510925399\n","Test Loss: 0.0011,\t Accuracy: (97.77%)\n","\n"]}]},{"cell_type":"markdown","source":["# Saving & Loading a Model"],"metadata":{"id":"vid1FiGGgmvE"}},{"cell_type":"markdown","source":["1. Option 1. store parameters & structures of the model\n","\n","2. Option 2. store each layers' parameters in a python dictionary\n","  - 이후 모델이 변경되어도 사용 가능\n","  - key: layer, value: model's weight\n","\n","3. Pre-trained weights and model from PyTorch"],"metadata":{"id":"azqV3xyRg_Ta"}},{"cell_type":"markdown","source":["# Preparing dataset(MNIST)"],"metadata":{"id":"Sg3LI2FXhOtm"}},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","train_data = datasets.MNIST(\n","    root = \"data\",\n","    train = True,\n","    download = True,\n","    transform = ToTensor()\n",")\n","\n","test_data = datasets.MNIST(\n","    root=\"data\",\n","    train=False,\n","    download = True,\n","    transform = ToTensor()\n",")\n","\n","# set data loader\n","batch_size = 64\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"J2y-7z57h0cC","executionInfo":{"status":"ok","timestamp":1682900023158,"user_tz":-540,"elapsed":13,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","network.to(device)\n","print(device)\n","\n","num_epochs = 3 #3번 돌면서 training을 하겠다.\n","optimizer = optim.SGD(network.parameters(), lr=1e-2, momentum=0.9)\n","train(network, optimizer, nn.CrossEntropyLoss(), train_loader, num_epochs, device) # 3번 트레이닝 한 다음에\n","test(network, nn.CrossEntropyLoss(), device) # 최종 결과를 얻는다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPfLTFvmm4PO","executionInfo":{"status":"ok","timestamp":1682900062941,"user_tz":-540,"elapsed":39794,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"da169f31-cd8f-4aa7-81b8-862cd6f9cefe"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n","Epoch: 1, Training Loss: 0.0005352937669920114\n","Epoch: 2, Training Loss: 0.0004619765471647649\n","Epoch: 3, Training Loss: 0.0003846111050195759\n","Test Loss: 0.0011,\t Accuracy: (98.0%)\n","\n"]}]},{"cell_type":"markdown","source":["# Save 하는 방법"],"metadata":{"id":"oN-05lpmnqvH"}},{"cell_type":"code","source":["# option 1\n","# save parameters & structure of model\n","\n","torch.save(network, \"./data/first_network\")\n","loaded_network = torch.load(\"./data/first_network\")\n","print(loaded_network)\n","print(type(loaded_network))"],"metadata":{"id":"UOXt6RGZqfJl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682900214471,"user_tz":-540,"elapsed":453,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"648b4b23-6baf-44e2-f62f-766a99be5887"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Net(\n","  (fc1): Linear(in_features=784, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=64, bias=True)\n","  (classifier): Linear(in_features=64, out_features=10, bias=True)\n",")\n","<class '__main__.Net'>\n"]}]},{"cell_type":"code","source":["# option 2\n","# maps of each layer's parameters\n","\n","torch.save(network.state_dict(), \"./data/first_network_dict\") # dictionary를 save\n","state_dict = torch.load(\"./data/first_network_dict\")\n","print(type(state_dict)) # 'collections'는 python 내부 library, python dictionary로 생각하면 된다.\n","\n","# key는 layer 이름\n","# 새로 추가해주는 additional_layer는 학습이 안 되어 있다. fc1, fc2, classifier는 학습이 된 layer\n","network.add_module(\"additional_layer\", nn.Linear(10,10))\n","print(*network.modules())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XcyeX7NOqyHr","executionInfo":{"status":"ok","timestamp":1682900516336,"user_tz":-540,"elapsed":268,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"d6fdb9df-0157-4554-ef11-de1ac94a90ec"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'collections.OrderedDict'>\n","Net(\n","  (fc1): Linear(in_features=784, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=64, bias=True)\n","  (classifier): Linear(in_features=64, out_features=10, bias=True)\n","  (additional_layer): Linear(in_features=10, out_features=10, bias=True)\n",") Linear(in_features=784, out_features=128, bias=True) Linear(in_features=128, out_features=64, bias=True) Linear(in_features=64, out_features=10, bias=True) Linear(in_features=10, out_features=10, bias=True)\n"]}]},{"cell_type":"code","source":["# strict = False ; strict하지 않게 불러오겠다. 안에 weight을 채워넣겠다.\n","network.load_state_dict(state_dict, strict=False)\n","# network.load_state_dict(state_dict, strict=True) # Raise Error!\n","print(network)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJYfNr_sr_sl","executionInfo":{"status":"ok","timestamp":1682900830507,"user_tz":-540,"elapsed":335,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"d21c6f0e-fbb9-4b47-f15a-78a588f6811a"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Net(\n","  (fc1): Linear(in_features=784, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=64, bias=True)\n","  (classifier): Linear(in_features=64, out_features=10, bias=True)\n","  (additional_layer): Linear(in_features=10, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["# predefine 된 모델\n","import torchvision.models as models\n","\n","resnet18 = models.resnet18(pretrained=True)\n","print(resnet18)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bT57LJoltG5y","executionInfo":{"status":"ok","timestamp":1682900974099,"user_tz":-540,"elapsed":816,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"56f376eb-5507-4e5a-c3a0-255781470a8f"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 196MB/s]"]},{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# 바로 가져다 쓸 수 없는 이유는 마지막 layer인 (fc) : Linear의 out_features가 1000이기 때문이다. \n","# 512 x 1000의 데이터, 1000개의 class를 가진 데이터에서 학습했기 때문이다.\n","\n","# 우리는 class가 10개이다. 그래서 마지막 layer를 바꿔줘야 한다.\n","# 그러면 pre-trained weight을 활용하면서 우리 데이터에 맞게 적용할 수 있다.\n","num_classes = 10\n","last_layer_in_features = resnet18.fc.in_features # 512개의 in_features를 받아오기 위한 것\n","resnet18.fc = nn.Linear(last_layer_in_features, num_classes) # 512에서 1000이 아니라 10으로 가는 것으로 바꿔치기\n","print(resnet18)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i8lw0bqEtvHc","executionInfo":{"status":"ok","timestamp":1682901212605,"user_tz":-540,"elapsed":280,"user":{"displayName":"­임도언 / 학생 / 데이터사이언스학과","userId":"11890332196499890561"}},"outputId":"aeecc04c-4c00-43c7-8dbd-61992f87feda"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OtaFlCUwujIR"},"execution_count":null,"outputs":[]}]}