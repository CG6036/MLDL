{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XY76eiyq7Yy9",
        "0h6jC2Fr7cvy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Part 1. Dot-product similarity"
      ],
      "metadata": {
        "id": "XY76eiyq7Yy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "N1raeVXBy_HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimension = 6\n",
        "word_dictionary = {\n",
        "    'I' : torch.ones(dimension),\n",
        "    'am' : torch.ones(dimension)*2,\n",
        "    'a' : torch.ones(dimension)*3,\n",
        "    'cat' : torch.ones(dimension)*4,\n",
        "    'dog' : torch.ones(dimension)*5,\n",
        "}\n",
        "\n",
        "data_1 = 'I am a cat'\n",
        "data_2 = 'I am a dog'\n",
        "\n",
        "for word, vector in word_dictionary.items():\n",
        "  print(f'{word} : {vector}')"
      ],
      "metadata": {
        "id": "btmbo0NR1aDi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4722e1-32de-4932-aabd-10d8da45d634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I : tensor([1., 1., 1., 1., 1., 1.])\n",
            "am : tensor([2., 2., 2., 2., 2., 2.])\n",
            "a : tensor([3., 3., 3., 3., 3., 3.])\n",
            "cat : tensor([4., 4., 4., 4., 4., 4.])\n",
            "dog : tensor([5., 5., 5., 5., 5., 5.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarity between two vectors"
      ],
      "metadata": {
        "id": "xRWeZ1PU4f5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We are going to get 'dot-product' similarity.\n",
        "# Let's start with vector-vector similarity.\n",
        "\n",
        "token_1 = word_dictionary['I']\n",
        "token_2 = word_dictionary['cat']\n",
        "\n",
        "print(token_1)\n",
        "print(token_2)"
      ],
      "metadata": {
        "id": "iQgzXXYJzBbH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27788c9b-904f-4edb-bedb-df14f6e6a3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1.])\n",
            "tensor([4., 4., 4., 4., 4., 4.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atVC2FrQfA70",
        "outputId": "28c281df-cf8b-4045-83ad-373588a6ce5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to calculate similarity between token_1 & token_2?\n",
        "# Answer should be a single scalar.\n",
        "\n",
        "######### Your Answer #########\n",
        "sim = token_1 @ token_2.T\n",
        "###############################\n",
        "\n",
        "print(sim.shape)\n",
        "print(sim)"
      ],
      "metadata": {
        "id": "OfMrQwZm2gx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f894c9-d82b-4ed4-ed23-9567754162da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([])\n",
            "tensor(24.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-e049e5cbe36d>:5: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3571.)\n",
            "  sim = token_1 @ token_2.T\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarity among vectors"
      ],
      "metadata": {
        "id": "CyyJNPWh4nMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now calculate similarities among all the words in a sentence,\n",
        "# 'I am a cat' (data_1)\n",
        "\n",
        "tokens = []\n",
        "for word in data_1.split():\n",
        "  tokens.append(word_dictionary[word])\n",
        "tokens = torch.stack(tokens, dim=0)\n",
        "\n",
        "print(tokens.shape)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "IvvJ5tDa3Wf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "968c3b17-1590-4539-e98f-da56e45e87d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 6])\n",
            "tensor([[1., 1., 1., 1., 1., 1.],\n",
            "        [2., 2., 2., 2., 2., 2.],\n",
            "        [3., 3., 3., 3., 3., 3.],\n",
            "        [4., 4., 4., 4., 4., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer should be [number_of_tokens x number_of_tokens] matrix.\n",
        "# number_of_tokens = 4\n",
        "\n",
        "######### Your Answer #########\n",
        "sim = tokens @ tokens.T\n",
        "###############################\n",
        "\n",
        "print(sim.shape)\n",
        "print(sim)"
      ],
      "metadata": {
        "id": "nz5fR49k41h6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a263824-8ac2-4cb8-9ac1-0ce3807141c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4])\n",
            "tensor([[ 6., 12., 18., 24.],\n",
            "        [12., 24., 36., 48.],\n",
            "        [18., 36., 54., 72.],\n",
            "        [24., 48., 72., 96.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarity among vectors in batch form"
      ],
      "metadata": {
        "id": "wjYT-Nji5Lxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now calculate similarities among all the words in two sentences,\n",
        "# 'I am a cat' & 'I am a dog (data_1 & data_2) in batch form.\n",
        "\n",
        "batch = []\n",
        "for data in [data_1, data_2]:\n",
        "  tokens = []\n",
        "  for word in data.split():\n",
        "    tokens.append(word_dictionary[word])\n",
        "  tokens = torch.stack(tokens, dim=0)\n",
        "  batch.append(tokens)\n",
        "batch = torch.stack(batch, dim=0)\n",
        "\n",
        "print(batch.shape)\n",
        "print(batch)"
      ],
      "metadata": {
        "id": "aFoPUgOB4OsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e8272a-1418-4946-e6a9-05a6005d2258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 6])\n",
            "tensor([[[1., 1., 1., 1., 1., 1.],\n",
            "         [2., 2., 2., 2., 2., 2.],\n",
            "         [3., 3., 3., 3., 3., 3.],\n",
            "         [4., 4., 4., 4., 4., 4.]],\n",
            "\n",
            "        [[1., 1., 1., 1., 1., 1.],\n",
            "         [2., 2., 2., 2., 2., 2.],\n",
            "         [3., 3., 3., 3., 3., 3.],\n",
            "         [5., 5., 5., 5., 5., 5.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer should be [batch x number_of_tokens x number_of_tokens] matrix.\n",
        "# batch = 2, number_of_tokens = 4\n",
        "\n",
        "######### Your Answer #########\n",
        "# batch shape : [batch, number_of_tokens, dimension]\n",
        "sim = batch @ batch.transpose(1,2) # or -2, -1\n",
        "###############################\n",
        "\n",
        "print(sim.shape)\n",
        "print(sim)"
      ],
      "metadata": {
        "id": "CNnJGFJd5mv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26b83e5-6df4-4e43-c739-98d789e4148b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 4])\n",
            "tensor([[[  6.,  12.,  18.,  24.],\n",
            "         [ 12.,  24.,  36.,  48.],\n",
            "         [ 18.,  36.,  54.,  72.],\n",
            "         [ 24.,  48.,  72.,  96.]],\n",
            "\n",
            "        [[  6.,  12.,  18.,  30.],\n",
            "         [ 12.,  24.,  36.,  60.],\n",
            "         [ 18.,  36.,  54.,  90.],\n",
            "         [ 30.,  60.,  90., 150.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 2. Attention mechanism"
      ],
      "metadata": {
        "id": "0h6jC2Fr7cvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "3DP9rvql6MPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimension = 6\n",
        "word_dictionary = {\n",
        "    'I' : torch.ones(dimension),\n",
        "    'am' : torch.ones(dimension)*2,\n",
        "    'a' : torch.ones(dimension)*3,\n",
        "    'cat' : torch.ones(dimension)*4,\n",
        "    'dog' : torch.ones(dimension)*5,\n",
        "}\n",
        "\n",
        "data_1 = 'I am a cat'\n",
        "data_2 = 'I am a dog'\n",
        "\n",
        "for word, vector in word_dictionary.items():\n",
        "  print(f'{word} : {vector}')"
      ],
      "metadata": {
        "id": "EWKZFZky7f_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d77221-39d7-43c4-c9ae-38f6d4fce1d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I : tensor([1., 1., 1., 1., 1., 1.])\n",
            "am : tensor([2., 2., 2., 2., 2., 2.])\n",
            "a : tensor([3., 3., 3., 3., 3., 3.])\n",
            "cat : tensor([4., 4., 4., 4., 4., 4.])\n",
            "dog : tensor([5., 5., 5., 5., 5., 5.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = []\n",
        "for data in [data_1, data_2]:\n",
        "  tokens = []\n",
        "  for word in data.split():\n",
        "    tokens.append(word_dictionary[word])\n",
        "  tokens = torch.stack(tokens, dim=0)\n",
        "  batch.append(tokens)\n",
        "batch = torch.stack(batch, dim=0)\n",
        "\n",
        "print(batch.shape)\n",
        "print(batch)"
      ],
      "metadata": {
        "id": "9xk6Zee77s1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea5078b-6de8-4637-8e35-1cc4f11031c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 6])\n",
            "tensor([[[1., 1., 1., 1., 1., 1.],\n",
            "         [2., 2., 2., 2., 2., 2.],\n",
            "         [3., 3., 3., 3., 3., 3.],\n",
            "         [4., 4., 4., 4., 4., 4.]],\n",
            "\n",
            "        [[1., 1., 1., 1., 1., 1.],\n",
            "         [2., 2., 2., 2., 2., 2.],\n",
            "         [3., 3., 3., 3., 3., 3.],\n",
            "         [5., 5., 5., 5., 5., 5.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch shape : [batch, number_of_tokens, dimension]\n",
        "# Use nn.Linear to make Query, Key & Value.\n",
        "# Remember, there will be no change in tensor shape.\n",
        "\n",
        "######### Your Answer #########\n",
        "to_query = nn.Linear(dimension, dimension)\n",
        "to_key = nn.Linear(dimension, dimension)\n",
        "to_value = nn.Linear(dimension, dimension)\n",
        "\n",
        "query = to_query(batch)\n",
        "key = to_key(batch)\n",
        "value = to_value(batch)\n",
        "###############################\n",
        "\n",
        "print(f'Query : {query.shape}')\n",
        "print(f'Key : {key.shape}')\n",
        "print(f'Value : {value.shape}')"
      ],
      "metadata": {
        "id": "JnBhn8Rx7kdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f3d0b7-2ae6-458f-c580-69f3f6e5ccc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query : torch.Size([2, 4, 6])\n",
            "Key : torch.Size([2, 4, 6])\n",
            "Value : torch.Size([2, 4, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement attention mechanism.\n",
        "# As you've done in part 1,\n",
        "# attention_score should be [batch x number_of_tokens x number_of_tokens]\n",
        "# contextualized_tokens should be [batch, number_of_tokens, dimension]\n",
        "\n",
        "######### Your Answer #########\n",
        "attention_score = query @ key.transpose(-2,-1)\n",
        "attention_score = attention_score.softmax(dim = -1) # 마지막 dimension.\n",
        "contextualized_tokens = attention_score @ value\n",
        "###############################\n",
        "\n",
        "print(f'attention_score : {attention_score.shape}')\n",
        "print(f'contextualized_tokens : {contextualized_tokens.shape}')"
      ],
      "metadata": {
        "id": "QA-emqph8UHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8342340-3f68-442e-ac34-4bc3fd9c094f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_score : torch.Size([2, 4, 4])\n",
            "contextualized_tokens : torch.Size([2, 4, 6])\n"
          ]
        }
      ]
    }
  ]
}